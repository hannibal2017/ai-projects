from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# åŠ è½½æœ¬åœ° DeepSeek
llm = Ollama(model="deepseek-r1")

# åˆ›å»º Prompt
prompt = PromptTemplate.from_template("1 + 1ç­‰äºå¤šå°‘ï¼š{question}")

# åˆ›å»º LangChain æ‰§è¡Œé“¾
chain = LLMChain(llm=llm, prompt=prompt)

# è¿è¡Œ AI ç”Ÿæˆä»£ç 
response = chain.invoke({"question": ""})
print(response)

# æå–æ–‡æœ¬å†…å®¹
formatted_text = response['text'] if isinstance(response, dict) and 'text' in response else str(response)

# æ ¼å¼åŒ–è¾“å‡º
print("\n" + "="*30)
print("ğŸ’¡ AI è®¡ç®—ç»“æœï¼š\n")
print(formatted_text)
print("="*30 + "\n")